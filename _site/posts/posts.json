[
  {
    "path": "posts/2021-10-20-predizendo-volume-de-eucalipto-com-tidymodels-xgboost-e-targets/",
    "title": "Predizendo volume de eucalipto com tidymodels, XGBoost e targets",
    "description": "\"Como montar um ambiente reprodutível para o ajuste de modelos de predição do volume de eucalipto.\"",
    "author": [
      {
        "name": "Theilon Macedo",
        "url": {}
      }
    ],
    "date": "2021-10-20",
    "categories": [],
    "contents": "\r\n\r\n\r\n\r\nFigure 1: Workflow do trabalho.\r\n\r\n\r\n\r\nUmas das dificuldades encontradas na academia é a reprodutibilidade de trabalhos. Essa é uma situação que, infelizmente, é corriqueira na área florestal. Neste texto, apresento algumas ferramentas que buscam melhorar a forma que trabalhos podem ser replicados, como a utilização dos pacotes here e renv.\r\nAproveitando o embalo, também mostro como usar o pacote tidymodels para a predição do volume de eucalipto. O dataset utilizado neste projeto é oriundo do excelente trabalho publicado no ano de 2020 pelo professor Gileno Azevedo juntamente com outros pesquisadores. O dataset pode ser encontrado na página do artigo. Vamos lá!\r\n1ª etapa - Iniciando o projeto\r\nAntes de qualquer coisa, preciso falar de 3 ferramentas básicas quando se busca reprodutibilidade em trabalhos no R:\r\nrenv\r\nEste pacote é um gerenciador de dependências: ele organiza e “memoriza” as dependências (como pacotes) que o seu projeto está usando de modo que, caso alguém refaça suas análises, não ocorra problemas como o uso de pacotes de versões distintas, além de tornar seu ambiente de trabalho isolado. Mais à frente explicarei outra importante vantagem. Caso queira saber mais sobre o renv, esse tutorial do Chaoran é show.\r\nR Projects\r\nÉ o mais simples dessa lista. Basicamente toda vez que você for criar um projeto, o ideal é que seja criada uma pasta principal e dentro dela serão criadas as demais pastas (data, R, etc.). Em seguida, abra o RStudio e crie um Project dentro desta pasta principal. A organização destas pastas terá a seguinte estrutura (a mesma utilizada neste trabalho):\r\n\r\n\r\n# Eucalipto_Volume (pasta principal)  \r\n#      |--Eucalipto_Volume.Rproj\r\n#      |--R  \r\n#      |--plots\r\n#      |--report\r\n\r\n\r\n\r\nhere\r\nEsse aqui é o mais legal: basicamente ele te permite criar caminhos relativos. Por ex.: ao invés de se referir a um arquivo como dados <- C:user/zezin/uma/duas/dados/meus_dados.csv, ou usar setwd(\"C:user/zezin/uma/duas/dados\"), prefira salvar seu Project em uma pasta principal e se referir a ele como here::here(\"dados\", \"meus_dados.csv\"). Isso facilita que outras pessoas reproduza suas análises sem grandes problemas. Tem um pessoal que recomenda fortemente usar o pacote here. Basicamente ele define o caminho de acesso aos arquivos a partir da última pasta do caminho (top-level folder), que no nosso exemplo hipotético é a pasta “dados”.\r\nMão na massa\r\nA primeira coisa que fiz foi criar uma pasta principal. Em seguida, criei dentro dela um R Project com o nome do meu projeto (Eucalipto_Volume). Então instalei o renv e executei o comando renv::init() para criar um ambiente local do projeto. A partir daí, iniciei as análises e instalei os pacotes básicos iniciais necessários (incluindo o here). Sempre que instalava um novo pacote, chamava renv::snapshot() para atualizar os estado do projeto e as dependências. Caso fosse necessário reverter alguma alteração de dependência no projeto após chamar renv::snapshot(), era acionado o comando renv::restore(). Pronto! Meu ambiente local do projeto está montado e isolado. Bacana, né?\r\n2ª etapa - Modelagem\r\nAgora a parte legal: a modelagem dos dados! Recentemente tem ganhado bastante tração um pacote de modelagem do R baseado na filosofia do tidyverse: o tidymodels. Esse pacote é incrível, permitindo usar diversos modelos de machine learning de forma extremamente intuitiva e bem elegante. A seguir vou mostrar o passo a passo necessário para ajustar e testar diversos modelos visando a predição do volume de eucalipto.\r\nCarregando os pacotes necessários:\r\n\r\n\r\nlibrary(here)\r\nlibrary(tidyverse)\r\nlibrary(tidymodels)\r\nlibrary(janitor)\r\nlibrary(EnvStats)\r\nlibrary(bestNormalize)\r\nlibrary(finetune)\r\nlibrary(doParallel)\r\nlibrary(extrafont)\r\n\r\n\r\n\r\nAquisição dos dados\r\nPrimeiramente serão adquiridas as bases de dados (treino e teste) a serem utilizadas no projeto a partir do site que disponibiliza o artigo e os dados. Aqui será criada uma pasta “data” onde os arquivos da base de dados serão baixados.\r\n\r\n\r\n# Criando o diretório onde a base será alocada\r\ndir.create(\"data\")\r\n\r\n# Acesso ao material\r\nlink_train <- \"https://doi.org/10.1371/journal.pone.0238703.s007\"\r\nlink_test <- \"https://doi.org/10.1371/journal.pone.0238703.s008\"\r\n\r\n# Aqui é criado o caminho de acesso às bases de dados\r\ndest_folder_train <- here::here(\"data\", \"train.xlsx\")\r\ndest_folder_test <- here::here(\"data\", \"test.xlsx\")\r\n\r\n# Aquisição da base de teste e treino usadas pelos autores do trabalho\r\nutils::download.file(link_train, \r\n                     destfile = dest_folder_train, \r\n                     mode = \"wb\")\r\n\r\nutils::download.file(link_test, \r\n                     destfile = dest_folder_test, \r\n                     mode = \"wb\")\r\n\r\n\r\n\r\nPerceba que aqui é usado o pacote here para a criação de um caminho relativo até a pasta de destino, em que o caminho até a pasta objetivo (neste caso, a pasta “data”) se inicia a partir da pasta principal criada para o projeto (Eucalipto_Volume), e não do seu diretório base. Caso a pasta principal do projeto seja alterada para outra partição, não será necessário chamar setwd() com um novo caminho.\r\nE qual a vantagem disso? Isso permite que você ou qualquer outra pessoa não precise alterar o caminho caso queira carregar/salvar as informações obtidas das mesmas análises aqui apresentadas. A utilização desse pacote é uma boa prática quando falamos de project-oriented workflows (workflow montado tendo como base projects).\r\nPreparando os dados\r\nAs bases de dados foram separadas originalmente pelos autores em dois arquivos. Essa é uma boa prática para criação de modelos e sua subsequente avaliação. Dividir os sets dessa forma permite que não ocorra data leakage (quando seu modelo, na fase de treino, “entra em contato” com os dados de teste, causando overfitting). Entretanto, uma vantagem do tidymodels é que ele permite o split entre set de treino e set de teste de forma unificada, sendo geradas partições de um mesmo arquivo sem a ocorrência de data leakage. Para ilustrar essa capacidade, os datasets serão unidos e então será mostrado como realizar a sua separação em treino e teste com o tidymodels:\r\n\r\n\r\n# Carregando a base de daoos separada\r\nsheet_train <- readxl::read_excel(here::here(\"data\", \"train.xlsx\"), \r\n                                  skip = 1)\r\nsheet_test <- readxl::read_excel(here::here(\"data\", \"test.xlsx\"), \r\n                                 skip = 1)\r\n\r\n# Unificando a base e \"limpando os nomes\" das colunas\r\ndataset <- \r\n    dplyr::bind_rows(sheet_train, sheet_test) |>\r\n    janitor::clean_names() |> \r\n    dplyr::mutate(across(c(stem:rotation), \r\n                         forcats::as_factor),\r\n                  across(c(tx, d), as.integer))\r\n\r\n\r\n\r\nIniciando o processo de modelagem\r\nApós unificar os dados, vamos colocar a mão na massa! A primeira coisa a ser feita é dividir os dados em treino e teste e então realizar a reamostragem repetida do set de treino para validação dos modelos. O tidymodels faz isso de forma prática:\r\n\r\n\r\nset.seed(1504)\r\n\r\nvol_split <- rsample::initial_split(data = dataset, \r\n                                    prop = 0.75, \r\n                                    strata = cod_volume)\r\ntrain_split <- rsample::training(vol_split)\r\ntest_split <- rsample::testing(vol_split)\r\n\r\n# Realizando validação cruzada repetida para avaliação dos modelos\r\nvol_folds <- rsample::vfold_cv(data = train_split, \r\n                               strata = cod_volume, \r\n                               repeats = 5)\r\n\r\n\r\n\r\nAlgumas considerações nessa etapa:\r\nO split inicial foi realizado usando uma proporção de 3/4.\r\nA divisão foi estratificada de acordo com as classes de volume comercial.\r\nO tidymodels permite a divisão do dataset de forma simples e que não ocorra data leakage, dispensando a necessidade de separar os dados manualmente.\r\nExplorando os dados\r\nNeste caso, temos um set de dados com poucos preditores: dbh (DAP) e h (Altura). Neste dataset também constam as variáveis tx e d que dizem respeito a se o volume de madeira predito é com casca ou sem casca (0 ou 1) e o diâmetro comercial, respectivamente. De modo a observar os padrões dos dados, vamos fazer uma análise exploratória básica das variáveis:\r\n\r\n\r\nggplot(data = train_split) +\r\n    geom_density(mapping = aes(x = dbh)) +\r\n    labs(x = \"DAP\")\r\n\r\nggplot(data = train_split) +\r\n    geom_density(mapping = aes(x = h)) +\r\n    labs(x = \"Altura\")\r\n\r\n# Explorando as relações entre as variáveis principais\r\nggplot(data = train_split) +\r\n    stat_count(mapping = aes(x = cod_volume))\r\n\r\nggplot(data = train_split) +\r\n    geom_point(mapping = aes(x = dbh, y = v))\r\n\r\nggplot(data = train_split) +\r\n    geom_point(mapping = aes(x = dbh^2, y = v))\r\n\r\nggplot(data = train_split) +\r\n    geom_point(mapping = aes(x = h^2, y = v))\r\n\r\nggplot(data = train_split) +\r\n    geom_point(mapping = aes(x = h, y = v))\r\n\r\nggplot(data = train_split) +\r\n    geom_point(mapping = aes(x = dbh*h, y = v))\r\n\r\nggplot(data = train_split) +\r\n    geom_point(mapping = aes(x = (dbh*h)^2, y = v))\r\n\r\nggplot(data = train_split) +\r\n    geom_point(mapping = aes(x = dbh, y = h))\r\n\r\n\r\n\r\nNeste caso, é recomendável normalizar os dados antes de seguir com a modelagem. Sem a padronização, uma variável pode ter um maior impacto sobre a resposta apenas por conta da sua escala, o que pode ser o caso aqui dadas as próprias unidades (cm e m) dos dados Essa normalização será aplicada mais à frente na modelagem.\r\nPode-se perceber também que a adição de interações e de termos quadráticos tornam a relação entre os preditores, especificamente dap e h, mais linear.\r\nTambém é possível observar que as classes de volume não possuem a mesma quantidade de observações. Neste caso, pode-se seguir com duas estratégias: a primeira seria ajustar um modelo para cada um dos diferentes volumes em separado; a segunda consiste na divisão ponderada (estratificação) no split dos dados (o treino e o teste teriam a mesma proporção de cada classe de volume). Neste trabalho, seguiremos a segunda estratégia.\r\nAjustando os modelos\r\nAgora vem a parte onde a mágica do tidymodels acontece: Primeiro é definida uma recipe do passo-a-passo que os dados devem ser processados. Em seguida são definidas as especificações modelos a serem utilizados. Serão definidas duas recipes (receitas de passo-a-passo): uma sem pré-processamento e outra pré-processada (com adião de interações, termos quadráticos e normalização):\r\n\r\n\r\n# Definindo os pré-processamentos dos dados\r\nsimple_vol_rec <- recipes::recipe(v ~ dbh + h + tx + d, data = train_split)\r\n\r\nnormalized_vol_rec <- simple_vol_rec |> \r\n  recipes::step_interact(terms = ~ dbh:h) |>  \r\n  recipes::step_mutate(dbh_sqrd = dbh^2, \r\n                       h_sqrd = h^2) |> \r\n  recipes::step_normalize(recipes::all_predictors(), -tx, -d)\r\n\r\n\r\n\r\nAqui pode-se perceber que a recipe normalized_vol_rec é apenas a recipe simple_vol_rec com mais “passos” adicionados.\r\nEm seguida, são definidos os diversos modelos a serem ajustados e depois testados. Estes modelos terão os hiperparâmetros mais importantes “marcados” para tunagem usando a função tune::tune.\r\n\r\n\r\n# Definindo diversos modelos\r\nlm_mod <- \r\n     parsnip::linear_reg() |> \r\n     parsnip::set_engine(\"lm\") |> \r\n     parsnip::set_mode(\"regression\")\r\n  \r\npenalized_lm_mod <- \r\n  parsnip::linear_reg(penalty = tune::tune(),\r\n                      mixture = tune::tune()) |> \r\n  parsnip::set_engine(\"glmnet\") |>\r\n  parsnip::set_mode(\"regression\")\r\n\r\nbag_mars_mod <- \r\n  baguette::bag_mars(prod_degree = tune::tune(), \r\n                     prune_method = \"exhaustive\",\r\n                     num_terms = tune::tune()) |> \r\n  parsnip::set_engine(\"earth\", times = 4) |> \r\n  parsnip::set_mode(\"regression\")\r\n  \r\ndec_tree <- \r\n  parsnip::decision_tree(cost_complexity = tune::tune(),\r\n                         tree_depth = tune::tune(),\r\n                         min_n = tune::tune()) |> \r\n  parsnip::set_engine(\"rpart\") |> \r\n  parsnip::set_mode(\"regression\")\r\n\r\nbag_cart_mod <- \r\n  baguette::bag_tree(cost_complexity = tune::tune(),\r\n                     tree_depth = tune::tune(),\r\n                     min_n = tune::tune()) |> \r\n  parsnip::set_engine(\"rpart\", times = 50L) |>\r\n  parsnip::set_mode(\"regression\")\r\n\r\nrf_spec <- \r\n  parsnip::rand_forest(mtry = tune::tune(), \r\n                       min_n = tune::tune(),\r\n                       trees = 1000) |> \r\n  parsnip::set_engine(\"ranger\") |> \r\n  parsnip::set_mode(\"regression\")\r\n  \r\nxgb_spec <- \r\n  parsnip::boost_tree(tree_depth = tune::tune(),\r\n                      learn_rate = tune::tune(),\r\n                      loss_reduction = tune::tune(),\r\n                      min_n = tune::tune(),\r\n                      sample_size = tune::tune(),\r\n                      mtry = tune::tune(),\r\n                      trees = 1000,\r\n                      stop_iter = 20) |> \r\n  parsnip::set_engine(\"xgboost\") |> \r\n  parsnip::set_mode(\"regression\")\r\n  \r\nsvm_r_spec <- \r\n  parsnip::svm_rbf(cost = tune::tune(),\r\n                   rbf_sigma = tune::tune(),\r\n                   margin = tune::tune()) |> \r\n    parsnip::set_engine(\"kernlab\") |> \r\n    parsnip::set_mode(\"regression\")\r\n  \r\nnnet_spec <- \r\n  parsnip::mlp(hidden_units = tune::tune(),\r\n               penalty = tune::tune(), \r\n               epochs = tune::tune()) |> \r\n    parsnip::set_engine(\"nnet\") |> \r\n    parsnip::set_mode(\"regression\")\r\n  \r\n  \r\nspecs_vol <- list(\"linear_reg\" = lm_mod, \r\n                  \"bag_mars\"= bag_mars_mod,\r\n                  \"decision_tree\" = dec_tree, \r\n                  \"bag_cart\" = bag_cart_mod, \r\n                  \"rf\" = rf_spec, \r\n                  \"xgb\" = xgb_spec,\r\n                  \"svm_rbf\" = svm_r_spec, \r\n                  \"nnet_mlp\" = nnet_spec,\r\n                  \"penalized_reg\" = penalized_lm_mod)\r\n\r\n\r\n\r\nTodas as especificações foram alocadas em uma lista que será usada mais à frente. Até aqui temos as duas recipes de pré-processamento a serem usadas nos dados e os 9 modelos especificados a serem tunados/ajustados.\r\nAgora vem a pergunta: como juntar tudo isso?\r\nEm um workflow (ou um workflowset, melhor dizendo).\r\n\r\n\r\n# Definindo o workflowset (serão ajustados 18 modelos ao todo)\r\nwflow_vol <- workflowsets::workflow_set(\r\n  models = specs_vol, #lista de modelos\r\n  preproc = list(\r\n    normalized = normalized_vol_rec,\r\n    simple = simple_vol_rec)\r\n  )\r\n\r\n\r\n\r\nCriado o workflowset, então será definida a configuração e o tipo de tunagem a ser aplicada. Neste caso, o processo de tunagem usado (race tuning) avalia todos os modelos em um set inicial da reamostragem. Baseado na performance corrente das métricas, alguns parâmetros que produzem modelos ruins, do ponto de vista preditivo, são então descartados na sequência do processo. Mais sobre esse processo de tunagem pode ser encontrado no livro do tidymodels.\r\n\r\n\r\n# Definindo as configurações da tunagem de parâmetros usando computação paralela\r\nracing_ctrl <- finetune::control_race(\r\n  save_pred = TRUE,\r\n  parallel_over = \"everything\",\r\n  save_workflow = TRUE\r\n)\r\n\r\n\r\n# Definindo a execução em paralelo \r\nclusters <- parallel::detectCores()\r\ncl <- parallel::makePSOCKcluster(clusters)\r\ndoParallel::registerDoParallel(cl)\r\n\r\n# Realizando a tunagem dos modelos\r\nresults_vol <-\r\n  workflowsets::workflow_map(\r\n    wflow_vol,\r\n    seed = 1504,\r\n    resamples = vol_folds,\r\n    control = racing_ctrl,\r\n    fn = \"tune_race_anova\",\r\n    grid = 25,\r\n    metrics = yardstick::metric_set(yardstick::rmse,\r\n                                    yardstick::rsq, \r\n                                    yardstick::huber_loss, \r\n                                    yardstick::mae)\r\n)\r\n# Parando a execução em paralelo \r\nparallel::stopCluster(cl)\r\nforeach::registerDoSEQ()\r\n\r\n\r\n\r\nApós realização da tunagem e escolhida a melhor configuração de parâmetros dos modelos de melhor desempenho, é feita a avaliação usando gráficos de acordo com as métricas definidas:\r\n\r\n\r\n# Plotagem dos resultados para cada métrica utilizada\r\nplot_results <- function(race_rslts, mtrc = \"rmse\",...){\r\n  workflowsets::autoplot(\r\n    race_rslts,\r\n    rank_metric = mtrc,  \r\n    metric = mtrc,       \r\n    select_best = TRUE,\r\n    ...\r\n    ) -> plot_racing\r\n  \r\n  ggplot2::ggsave(glue::glue(mtrc, \".png\"), \r\n                  path = here::here(\"plots\"))\r\n  graphics::plot(plot_racing)\r\n  \r\n}\r\n\r\nplot_results(results_vol, mtrc = \"rsq\")\r\nplot_results(results_vol, mtrc = \"rmse\")\r\nplot_results(results_vol, mtrc = \"huber_loss\")\r\nplot_results(results_vol, mtrc = \"mae\")\r\n\r\n\r\n\r\nAvaliação da qualidade dos modelos\r\nEm seguida, deve ser realizada a seleção do melhor modelo. Para isso, são criadas funções de:\r\nSeleção do melhor modelo.\r\nAjuste final do modelo selecionado.\r\nObtenção das métricas de avaliação do modelo selecionado no set de teste.\r\n\r\n\r\n# Função para seleção de modelos de acordo com o R² (padrão)\r\nselect_models <- function(grid_results, metric = \"rsq\", rank_posit = 1){\r\n  \r\n  workflowsets::rank_results(grid_results, \r\n                             select_best = TRUE) |> \r\n  dplyr::relocate(rank) |> \r\n  dplyr::select(-c(.config, model, std_err)) |> \r\n  dplyr::filter(.metric == \"rsq\" & rank == rank_posit) -> model_selected\r\n  EnvStats::print(model_selected)\r\n  \r\n}\r\n\r\n# Função para ajuste final do modelo\r\nfit_model <- function(grid_results, model_ranked, df_split, metric = \"rmse\"){\r\n    \r\n    name_model <- model_ranked |> purrr::pluck(\"wflow_id\", 1)\r\n  \r\n    model <- grid_results |> \r\n        workflowsets::extract_workflow_set_result(id = name_model) |>\r\n        tune::select_best(metric = metric)\r\n    \r\n    grid_results |> \r\n        workflowsets::extract_workflow(name_model) |>\r\n        tune::finalize_workflow(model) |> \r\n        tune::last_fit(split = df_split,\r\n                       metrics = yardstick::metric_set(yardstick::rmse, \r\n                                                       yardstick::rsq, \r\n                                                       yardstick::huber_loss, \r\n                                                       yardstick::mae))\r\n    \r\n}\r\n\r\n# Função para obtenção da performance do melhor modelo no set de teste\r\nmetrics_mod <- function(best_mod, model_ranked){\r\n  \r\n  name_model <- model_ranked |> purrr::pluck(\"wflow_id\", 1)\r\n  \r\n  workflowsets::collect_metrics(best_mod) |> \r\n    kableExtra::kbl(caption = glue::glue(\"Performance do modelo \", \r\n                                         name_model)) |> \r\n    kableExtra::kable_classic(full_width = F, \r\n                              html_font = \"Cambria\", \r\n                              font_size = 16) |> \r\n    kableExtra::save_kable(file = here::here(\"plots\", \r\n                                             glue::glue(\"perf_\", \r\n                                                        name_model, \r\n                                                        \".png\")),\r\n                           self_contained = T)\r\n  \r\n  workflowsets::collect_metrics(best_mod)\r\n}\r\n\r\n# Seleção, ajuste e avaliação do melhor modelo\r\nbest_model <- select_models(grid_results = results_vol)\r\n\r\nfit_best_mod <- fit_model(grid_results = results_vol,\r\n                        model_ranked = best_model,\r\n                        df_split = vol_split)\r\n\r\nmetrics_mod(fit_best_mod, best_model)\r\n\r\n\r\n\r\nFigure 2 - Desempenho dos modelos.De modo a termos um ponto de comparação didático, serão comparados um modelo de qualidade intermediária e o melhor modelo. Esse processo se dá de forma similar ao realizado previamente, exceto que agora será selecionado o modelo ranqueado na posição número 10 (rank_posit = 1) em contraste ao melhor modelo (rank_posit = 1):\r\n\r\n\r\n# Seleção, ajuste e avaliação do modelo intermediário\r\nintermediary_model <- select_models(grid_results = results_vol, rank_posit = 10)\r\n\r\nfit_intermediary_model <- fit_model(grid_results = results_vol,\r\n                                       model_ranked = intermediary_model,\r\n                                       df_split = vol_split)\r\n\r\nmetrics_mod(fit_intermediary_model, intermediary_model)\r\n\r\n\r\n\r\nAgora ambos os modelos ajustados previamente serão comparados através de gráficos de dispersão contendo o volume predito vs volume observado, permitindo uma análise visual da qualidade preditiva de cada um. Para isso serão definidas duas funções para geração do gráfico de dispersão de cada modelo.\r\n\r\n\r\n# Função para plotar os resultados dos modelos\r\nscatterplot <- function(.x, .y){\r\n    \r\n    ggplot2::ggplot(.x) + \r\n        ggplot2::geom_point(mapping = ggplot2::aes(x = .pred, y = v)) + \r\n        ggplot2::geom_point(mapping = ggplot2::aes(x = .pred, y = v), \r\n                   alpha = 0.5, \r\n                   size = 2, \r\n                   color = \"black\", \r\n                   fill = \"mediumspringgreen\", \r\n                   pch = 21) + \r\n        ggplot2::geom_abline(lty = 2, \r\n                    col = \"black\", \r\n                    size = 1) +\r\n        tune::coord_obs_pred() +\r\n        ggplot2::theme_classic() +\r\n        ggplot2::theme(text = ggplot2::element_text(family = \"Source Code Pro\")) +\r\n        ggplot2::ggtitle(.y) +\r\n        ggplot2::labs(x = \"Volume Predito (m³)\",\r\n                      y = \"Volume Observado (m³)\") -> plot_scatterplot\r\n    \r\n  ggplot2::ggsave(glue::glue(.y, \".png\"), path = here::here(\"plots\"))\r\n  graphics::plot(plot_scatterplot)\r\n  \r\n}\r\n\r\n# Função para extrair os dados preditos e plotá-los vs os \r\n# dados observados usando a função anterior\r\naccessing_models <- function(mod1, mod2, model_ranked1, model_ranked2){\r\n    \r\n    gsub_und <- function(x) gsub(\"_\", \" \", x)\r\n    name_model1 <- model_ranked1 |> purrr::pluck(\"wflow_id\", 1) |> gsub_und()\r\n    name_model2 <- model_ranked2 |> purrr::pluck(\"wflow_id\", 1) |> gsub_und()\r\n    \r\n    workflowsets::collect_predictions(mod1) |> \r\n        dplyr::mutate(model = name_model1) |> \r\n        dplyr::bind_rows(workflowsets::collect_predictions(mod2) |> \r\n                      dplyr::mutate(model = name_model2)) |>\r\n        tidyr::nest(data = -c(model)) |> \r\n        dplyr::mutate(plots = map2(data, model, scatterplot))\r\n    \r\n}\r\n\r\naccessing_models(fit_best_mod, \r\n                 fit_intermediary_model, \r\n                 best_model, \r\n                 intermediary_model)\r\n\r\n\r\n\r\nFigure 3 - Volume observado vs volume predito usando o modelo XGBoost.Conclusão da modelagem\r\nÉ possível observar que o modelo XGBoost com pré-processamento normalizado apresentou um desempenho elevado frente aos demais modelos, apontando a sua aplicabilidade para a predição de volume de madeira de eucalipto em florestas plantadas. É digno de nota que, de forma similar ao que foi apontado por Azevedo et al. (2020), o modelo de redes neurais artificiais (MLP) apresentou um R² de ~0,96.\r\n3ª etapa - Reprodutibilidade\r\nAgora vamos para etapa que foca no uso do pacote targets. Com o targets pode ser mantido uma rotina de trabalho reprodutível que evita ao máximo repetições. O pacote “aprende” como o seu fluxo de trabalho se encaixa e pula a execução de tarefas pesadas que já estão atualizadas. Desse modo, ele executa apenas as etapas necessárias ou que foram alteradas/adicionadas. Mais informações sobre esse pacote podem ser encontradas em seu manual.\r\nE como o targets funciona?\r\nBasicamente ele depende de funções:\r\nPara todas as etapas da modelagem que foi realizada foi criada uma função que foi alocada em um script (functions.R), assim, o fluxo de trabalho é subdividido e pode rodar de forma mais independente. Lembra da pasta “Eucalipto_Volume/R” criada lá no começo? Então, dentro dessa pasta é onde está o script com as funções definidas. Esse script pode ser acessado aqui. Um exemplo de função criada para a modelagem foi a da criação da base de dados na pasta “data”:\r\n\r\n\r\nreadind_data <- function(){\r\n    \r\n    dir.create(\"data\")\r\n    \r\n    link_train <- \"https://doi.org/10.1371/journal.pone.0238703.s007\"\r\n    link_test <- \"https://doi.org/10.1371/journal.pone.0238703.s008\"\r\n    \r\n    dest_folder_train <- here::here(\"data\", \"train.xlsx\")\r\n    dest_folder_test <- here::here(\"data\", \"test.xlsx\")\r\n    \r\n    utils::download.file(link_train, \r\n                         destfile = dest_folder_train, \r\n                         mode = \"wb\") # wb se OS for Windows\r\n    utils::download.file(link_test, \r\n                         destfile = dest_folder_test, \r\n                         mode = \"wb\")\r\n    \r\n    sheet_train <- readxl::read_excel(dest_folder_train, skip = 1)\r\n    sheet_test <- readxl::read_excel(dest_folder_test, skip = 1)\r\n    \r\n    dplyr::bind_rows(sheet_train, sheet_test) |> \r\n        janitor::clean_names() |>  \r\n        dplyr::mutate(across(c(stem:rotation), \r\n                             forcats::as_factor),\r\n                      across(c(tx, d), as.integer))\r\n    \r\n}\r\n\r\n\r\n\r\nAs demais funções seguem esse mesmo estilo.\r\nUsando o targets\r\nÉ agora que o targets entra na brincadeira de vez. Para orquestrar o fluxo de trabalho primeiramente deve ser criado um script (_targets.R) alocado dentro da pasta principal (“Eucalipto_Volume”). Neste script são carregados os pacotes targets e tarchetypes (falo dele mais à frente), também é deve ser carregado o script com as funções definidas na etapa anterior e alocado na pasta “R”, a partir da função base::source() (perceba o uso do pacote here):\r\n\r\n\r\nlibrary(targets)\r\nlibrary(tarchetypes)\r\nsource(here::here(\"R\", \"functions.R\"))\r\n\r\n\r\n\r\nEm seguida, deve ser criada uma lista tendo os targets como elementos usando a função targets::tar_targets() em que o seu primeiro argumento é o nome do target a ser criado e o segundo é a função do script “functions.R” a ser usada, no seguinte esquema:\r\n\r\n\r\nlist(targets::tar_target(nome_do_target_1, funcao_a_ser_executada()), # 1\r\n     targets::tar_target(nome_do_target_2, funcao_a_ser_executada(nome_do_target_1))) # 2\r\n\r\n\r\n\r\nA função usada dentro do targets::tar_targets() geralmente requer como argumento o nome do target anterior, como no caso 2. Entretanto, targets que iniciam o fluxo de trabalho (caso 1) ou que não estão ligadas diretamente aos produtos intermediários da computação não requerem que seja passado algum argumento à sua função.\r\nNeste trabalho, a lista completa de targets definidos de acordo com as funções pode ser observada a seguir:\r\n\r\n\r\nlist(\r\n    targets::tar_target(packages, packages_used()),\r\n    targets::tar_target(dataset, readind_data()),\r\n    targets::tar_target(vol_split, split_data(dataset, 1504, 0.75, cod_volume)),\r\n    targets::tar_target(test_split, test_set_split(vol_split)),\r\n    targets::tar_target(train_split, train_set_split(vol_split)),\r\n    targets::tar_target(vol_resamples, kfold_cv(train_split, strata = cod_volume, repeats = 5)),\r\n    targets::tar_target(normalized_vol_rec, preproc_rec(train_split)),\r\n    targets::tar_target(simple_vol_rec, simple_rec(train_split)),\r\n    targets::tar_target(all_specs, def_specs()),\r\n    targets::tar_target(wflow_vol, workflow_config(all_specs, normalized_vol_rec, simple_vol_rec)),\r\n    targets::tar_target(racing_ctrl, racing_defs()),\r\n    targets::tar_target(results_vol, race_tuning(wflow_vol, vol_resamples, racing_ctrl, 1504)),\r\n    targets::tar_target(plot_rsq, plot_results(results_vol, \"rsq\")),\r\n    targets::tar_target(best_model, select_models(results_vol, \"rmse\", 1)),\r\n    targets::tar_target(intermediary_model, select_models(results_vol, \"rmse\", 10)),\r\n    targets::tar_target(fit_best_mod, fit_model(results_vol, best_model, vol_split)),\r\n    targets::tar_target(fit_intermediary_model, fit_model(results_vol, intermediary_model, vol_split)),\r\n    targets::tar_target(metrics_best, metrics_mod(fit_best_mod, best_model)),\r\n    targets::tar_target(metrics_intermediary, metrics_mod(fit_intermediary_model, intermediary_model)),\r\n    targets::tar_target(model_comparison, accessing_models(fit_best_mod,\r\n                                                           fit_intermediary_model, \r\n                                                           best_model, \r\n                                                           intermediary_model)),\r\n    tarchetypes::tar_render(report, here::here(\"report\", \"report.Rmd\"))\r\n)\r\n\r\n\r\n\r\nEssa lista possui alguns pontos dignos de destaque:\r\nO targets possui algumas ferramentas de avaliação do fluxo de trabalho estabelecido, e uma das mais legais é a função targets::tar_visnetwork. Ela permite que o pipeline seja inspecionado a partir de um fluxograma que informa se os targets estão atualizados ou não.\r\nFigure 4 - Network para inspeção do pipeline criado. Círculo em cor cinza signfica que que o target está desatualizado ou passou por algum ajuste (deve ser computado via targets::tar_make()); círculo laranja indica que há algum erro no pipeline; círculo verde indica que o target está atualizado (up-to-date).Ao fim da lista, o target tarchetypes::tar_render permite que um relatório seja gerado a partir de um arquivo “.Rmd”. Assim, foi produzido um relatório simples, usando rmardown, visando ser uma amostra do que pode ser feito a partir desse orquestramento de trabalho. Esse exemplo pode ser expandido para a produção de um artigo acadêmico ou um relatório mais complexo. Dessa forma, pode-se realizar as análises do trabalho e gerar o material final em um único pipeline. No corpo do relatório produzido, foram adicionados chamados aos 3 penúltimos objetos da lista de targets (metrics_best, metrics_intermediary, model_comparison) usando a função targets::tar_read(), em que estes objetos targets são lidos dentro do relatório. Isso é necessário para que a função tarchetypes::tar_render saiba que o relatório só poderá ser produzido quando todas as análises do pipeline forém finalizadas e estes três últimos objetos gerados.\r\nOutro ponto digno de nota é que esse processamento pode levar um tempo para ser computado. Com isso, rodá-lo novamente pode ser bem tedioso. Uma vantagem do targets é que ele memoriza os passos realizados e guarda os produtos obtidos. Dessa forma, caso seja realizada alguma alteração no pipeline, ele roda apenas as análises diretamente afetadas pela alteração feita. Por exemplo: caso seja adicionado um novo modelo na função def_specs(), que consta no arquivo functions.R, todas as análises diretamente afetadas por esse passo serão computadas novamente, porém os passos anteriores ao seu chamado não são recomputados, reduzindo o tempo e otimizando o trabalho.\r\nReproduzindo o pipeline\r\nApós realização da modelagem e orquestramento do trabalho, resta a sua publicação para que outras pessoas possam reproduzi-lo. Isso é feito de uma forma bem simples graças ao renv e ao targets. Basta clonar o repositório e salvá-lo em uma pasta principal, preferencialmente. Então, basta abrir o arquivo R Project (Eucalipto_Volume.Rproj) no RStudio e executar os seguintes comandos para instalar todos os pacotes necessários e rodar o pipeline, respectivamente:\r\n\r\n\r\nrenv::restore() # Pode demorar um pouco\r\ntargets::tar_make() # Roda o pipeline\r\n\r\n\r\n\r\nCaso você queira inspecionar o pipeline, para acompanhar o processo ou onde possa ter ocorrido possíveis falhas, basta chamar:\r\n\r\n\r\ntargets::tar_visnetwork() # Apresenta o diagrama de execução\r\n\r\n\r\n\r\nConclusão (UFA!)\r\nEssa foi uma introdução (espero que não muito cansativa) à uma das formas de utilização de modelos de machine learning com o tidymodels e de como aumentar a reprodutibilidade de trabalhos com os pacotes here, renv e targets. Confesso que esse projeto foi um trabalho bem bacana de realizar e utilizar estes pacotes se mostrou uma experiência super enriquecedora.\r\nAgradeço quem chegou até o final. Até mais!\r\nReferências\r\nAzevedo, G. B. et al. Multi-volume modeling of Eucalyptus trees using regression and artificial neural networks. Plos one, v. 15, n. 9, p. e0238703, 2020.\r\nKuhn, M., Silge, J., 2021. Tidy Modeling with R. URL: https://www.tmwr.org/\r\n\r\n\r\n\r\n",
    "preview": "posts/2021-10-20-predizendo-volume-de-eucalipto-com-tidymodels-xgboost-e-targets/featured.jpg",
    "last_modified": "2021-10-20T01:10:52-03:00",
    "input_file": {}
  },
  {
    "path": "posts/2021-10-20-xgboost-com-python-para-biometria-florestal/",
    "title": "XGBoost com Python para biometria florestal",
    "description": "Como ajustar um modelo XGBoost para predição do volume de eucalipto.",
    "author": [
      {
        "name": "Theilon Macedo",
        "url": {}
      }
    ],
    "date": "2021-10-20",
    "categories": [],
    "contents": "\r\nNo último texto que escrevi, o XGBoost foi o melhor modelo ajustado dentre todos os que foram testados. Um colega que leu o texto me solicitou um auxílio para ajustar este modelo usando Python, já que essa é a linguagem que ele possui maior domínio. Então decidi aproveitar e escrever um breve tutorial sobre esse ajuste.\r\nO dataset aqui utilizado é oriundo do excelente trabalho publicado publicado por Azevedo et al. (2020).\r\nAprendendo com os erros\r\nXGBoost (eXtreme Gradient Boosting) é uma implementação eficiente do algoritmo gradient boosted trees. Este algoritmo é um dos mais usados atualmente dada a sua elevada capacidade preditiva, além de ter como ponto forte a sua escalabilidade em diversos cenários.\r\nDe forma geral, os algoritmos gradient boosting atuam de modo a predizer uma variável resposta a partir da combinação de estimativas de um set de modelos fracos.\r\nO processo de treinamento desses modelos se dá de forma iterativa, em que são adicionada novas árvores de decisão que tem o objetivo de predizer os resíduos das árvores estabelecidas previamente, “aprendendo” com erros das árvores ajustadas anteriormente. São chamados de gradient boosting models por usarem o algoritmo de gradiente descendente para minimizar a função de perda. Mais informações sobre esses algoritmos podem ser encontradas aqui, aqui, aqui e aqui.\r\nAjustando o modelo\r\nImportando as bibliotecas necessárias:\r\n\r\nfrom xgboost import XGBRegressor\r\nfrom sklearn import metrics\r\nfrom sklearn.model_selection import train_test_split\r\nimport pandas as pd\r\nimport matplotlib.pyplot as plt\r\nimport numpy as np\r\nimport pickle\r\n\r\nNeste caso, o dataset já estava particionado. Porém, optei por realizar a sua unificação de modo a seguir o padrão estipulado no texto anterior.\r\n\r\ntraining = pd.read_excel('data/train.xlsx', skiprows=1)\r\ntesting = pd.read_excel('data/test.xlsx', skiprows=1)\r\n\r\ndf = training.append(testing)\r\n\r\nX = df.filter(items=[\"DBH\", \"H\", \"TX\", \"d\"]).values.reshape(-1, 4)\r\ny = df.filter(items=[\"V\"])\r\n\r\nParticionando os dados em treino e teste com estratificação de acordo com o volume comercial:\r\n\r\nX_train, X_test, y_train, y_test = train_test_split(X, y, \r\n                                                    test_size=0.25, \r\n                                                    random_state=1504,\r\n                                                    stratify=df.Cod_Volume)\r\n\r\nEm seguida, defini o modelo e seus hiperparâmetros. Optei por não realizar a tunagem destes hiperparâmetros e usar os valores já definidos no último tutorial:\r\n\r\nmodel = XGBRegressor(\r\n    objective='reg:squarederror',\r\n    n_estimators=2000,\r\n    max_depth=7,\r\n    learning_rate=0.0367,\r\n    n_jobs=10,\r\n    gamma=0.0000806,\r\n    booster=\"gbtree\",\r\n    min_child_weight=20\r\n    )\r\n\r\nFeita esta estapa, resta ajustar o modelo com os dados de treino:\r\n\r\nmodel.fit(X_train, y_train)\r\n\r\nRealizado o ajuste, agora será realizada a predição dos dados de teste para comparação e avaliação da qualidade do modelo:\r\n\r\npredicted_vol = model.predict(X_test)\r\n\r\n# Avaliação da qualidade do modelo usando o R²\r\nprint(\"Coeficiente de determinação - R²:\", metrics.r2_score(y_test, predicted_vol))\r\n\r\nO modelo apresentou um R² bastante elevado, indicando potencial de uso para a predição do volume de eucalipto.\r\nObtendo uma apresentação visual dos resultados do volume predito com o modelo XGBoost e observado em campo:\r\n\r\nplt.figure(figsize=(8, 7), dpi=300)\r\nplt.scatter(model_results[\"actual\"], \r\n            model_results[\"predicted\"],\r\n            s=15, \r\n            edgecolors='black', \r\n            linewidth=0.4, \r\n            alpha=0.6)\r\nplt.title(\"Volumetria Eucalipto - Modelo XGBoost\")\r\nplt.xlabel(\"Volume observado (m³)\")\r\nplt.ylabel(\"Volume predito (m³)\")\r\nz = np.polyfit(model_results[\"actual\"], \r\n               model_results[\"predicted\"], \r\n               1)\r\np = np.poly1d(z)\r\nplt.plot(model_results[\"predicted\"], \r\n         p(model_results[\"predicted\"]), \r\n         \"r--\", \r\n         color=\"black\")\r\n\r\nVolume (m³) de eucalipto observado vs predito.Como podemo concluir que o modelo generaliza bem, basta ajustá-lo usando toda a base de dados:\r\n\r\nmodel.fit(X, y)\r\n\r\nPronto! Agora basta escolher a melhor forma de salvar seu modelo seja usando pickle ou joblib (papo para outro texto).\r\nReferências\r\nAzevedo, G. B. et al. Multi-volume modeling of Eucalyptus trees using regression and artificial neural networks. Plos one, v. 15, n. 9, p. e0238703, 2020.\r\nhttps://estatsite.com.br/2020/10/03/xgboost-em-python/\r\nJames, G. et al. An introduction to statistical learning. New York: springer, 2013.\r\nhttps://xgboost.readthedocs.io/en/latest/\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2021-10-20T01:50:21-03:00",
    "input_file": "xgboost-com-python-para-biometria-florestal.knit.md"
  }
]
